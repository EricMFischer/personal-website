---
title: Generative Recurrent Language Models with MCMC Inference
summary: Utilizes image parsing to text description framework that generates text descriptions based on understanding of image and video content
tags:
- Markov Chain Monte Carlo
- Natural Language Processing
- Generative Modeling
- RNN
- Sequence Model
date: "2019-10-10T00:00:00Z"
# featured: true

# Optional external URL for project (replaces project detail page).
external_link: ""

# Featured image
# To use, place an image named `featured.jpg/png` in your page's folder.
# Placement options: 1 = Full column width, 2 = Out-set, 3 = Screen-width
# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
# Set `preview_only` to `true` to just use the image for thumbnails.
image:
  placement: 1
  caption: Text generation example (stat.ucla.edu/~sczhu/papers/TMM_Topic_Clustering_Tracking.pdf)
  focal_point: Smart
  preview_only: false

url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides: example
---
I **co-authored** this paper, soon under review at a top conference in NLP, while advised by Dr. Song-Chun Zhu at the Center for Vision, Cognition, Learning, and Autonomy at UCLA.

**Please note** the image above is taken from a related [paper](http://www.stat.ucla.edu/~sczhu/papers/TMM_Topic_Clustering_Tracking.pdf) at the Vision, Cognition, Learning, and Autonomy lab at UCLA.

More information about this paper will be posted here after the final version is published to Arxiv.

# {{< figure src="1.png" lightbox="true" width="90%" height="90%">}}
